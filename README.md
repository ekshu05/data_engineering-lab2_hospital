# data_engineering-lab2_hospital
ğŸ“‚ File Organisation

Lab-2/
â”‚
â”œâ”€â”€ hospital/
â”‚   â”œâ”€â”€ raw_data/                         # Input files
â”‚   â”‚   â”œâ”€â”€ patients_data_with_doctor.csv
â”‚   â”‚   â”œâ”€â”€ doctors_info.csv
â”‚   â”‚   â””â”€â”€ patient_feedback.json
â”‚   â”‚
â”‚   â”œâ”€â”€ da.py                             # Business Analyst script (questions + data needs)
â”‚   â”œâ”€â”€ ml.py                             # Data Engineer script (ETL pipeline)
â”‚   â””â”€â”€ README.md                         # Documentation (this file)
â”‚
â””â”€â”€ data_warehouse/                       # Output folder (auto-created)
    â””â”€â”€ processed_patient_data.csv         # Final processed dataset



ğŸ¥ Hospital Dataset â€“ ETL Pipeline

This project integrates patients, doctors, and feedback data to provide a complete view of patient care. The pipeline includes Business Analysis (questions + requirements) and Data Engineering (ETL process).

ğŸ”¹ Stage 1: Business Analyst Task

Business Question:
How do patients, doctors, and feedback data combine to give a full view of patient care?

Required Data Points:

patient_id

doctor_id

doctor_name

treatment_id

feedback_score

ğŸ”¹ Stage 2: Data Engineer Task

The ETL pipeline consists of Ingestion â†’ Cleansing â†’ Transformation â†’ Loading.

1ï¸âƒ£ Ingestion

Read data from multiple sources:

Patients dataset â†’ patients_data_with_doctor.csv

Doctors dataset â†’ doctors_info.csv

Feedback dataset â†’ patient_feedback.json

patients_df = pd.read_csv("hospital/raw_data/patients_data_with_doctor.csv")
doctors_df = pd.read_csv("hospital/raw_data/doctors_info.csv")
feedback_df = pd.read_json("hospital/raw_data/patient_feedback.json", lines=False)

2ï¸âƒ£ Cleansing

Drop duplicate records from all datasets.

Handle missing feedback scores (replace with 0).

Standardize column names to lowercase.

patients_df = patients_df.drop_duplicates()
doctors_df = doctors_df.drop_duplicates()
feedback_df = feedback_df.drop_duplicates()

feedback_df["feedback_score"] = feedback_df["feedback_score"].fillna(0)

patients_df.columns = [c.strip().lower() for c in patients_df.columns]
doctors_df.columns = [c.strip().lower() for c in doctors_df.columns]
feedback_df.columns = [c.strip().lower() for c in feedback_df.columns]

3ï¸âƒ£ Transformation

Merge patients with doctors on doctor_id.

Merge with feedback on patient_id and treatment_id.

merged_df = patients_df.merge(doctors_df, on="doctor_id", how="left")

if {"patient_id", "treatment_id"}.issubset(feedback_df.columns):
    merged_df = merged_df.merge(
        feedback_df, on=["patient_id", "treatment_id"], how="left"
    )

4ï¸âƒ£ Loading

Store the processed dataset into a data warehouse folder.

import os
os.makedirs("data_warehouse", exist_ok=True)

merged_df.to_csv("data_warehouse/processed_patient_data.csv", index=False)


âœ… Output File:
data_warehouse/processed_patient_data.csv




ğŸš€ Steps to Run

Navigate to the project folder:

cd Lab-2/hospital


Ensure raw data is present inside hospital/raw_data/.

Run the ETL script:

python ml.py


Check output in:

data_warehouse/processed_patient_data.csv
